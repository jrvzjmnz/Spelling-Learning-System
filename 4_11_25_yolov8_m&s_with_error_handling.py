# -*- coding: utf-8 -*-
"""4/11/25 YOLOv8 M&S with error Handling.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yrcbna6xr4fVCaskSM7GhxJp_tE75P9Y

# YOLOv8s
"""

!pip install ultralytics roboflow

!pip install roboflow

from roboflow import Roboflow
rf = Roboflow(api_key="otK6vYnKBd28x5kqa8zS")
project = rf.workspace("rsfesfdse").project("dl-yolo-v5")
version = project.version(6)
dataset = version.download("yolov8")

from ultralytics import YOLO

model = YOLO('yolov8m.pt')  # or 'yolov8s.pt' for faster but slightly less accurate
model.train(data="/content/DL-YOLO-V5-5/data.yaml", epochs=100, imgsz=640, batch=16)

# ✅ Best model will be saved here:
# runs/detect/train/weights/best.pt

model.val()

"""# Testing"""

# ✅ Step 1: Install Ultralytics YOLOv8 if not already installed
!pip install -q ultralytics

# ✅ Step 2: Import YOLO
from ultralytics import YOLO
import matplotlib.pyplot as plt
import cv2
import os

# ✅ Step 3: Paste your model path and image path here
model_path = '/content/Current DL YOLOv8s with error handling ni loraine.pt'  # <- Replace with your model file path
image_path = '/content/cat.jpg'  # <- Replace with your image file path

# ✅ Step 4: Load model and perform prediction
model = YOLO(model_path)
results = model(image_path, save=True, imgsz=640, conf=0.7)  # You can change conf threshold

# ✅ Step 5: Display the image with bounding boxes
# YOLO saves the result image in 'runs/detect/predict' by default
output_dir = results[0].save_dir
output_img_path = os.path.join(output_dir, os.path.basename(image_path))

# Use OpenCV to read and display the image
img = cv2.imread(output_img_path)
img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

plt.figure(figsize=(10, 10))
plt.imshow(img_rgb)
plt.axis('off')
plt.title("YOLOv8 Detection Output")
plt.show()



"""# YOLOv8m Training"""



!pip install ultralytics roboflow

!pip install roboflow

from roboflow import Roboflow
rf = Roboflow(api_key="otK6vYnKBd28x5kqa8zS")
project = rf.workspace("rsfesfdse").project("dl-yolo-v5")
version = project.version(6)
dataset = version.download("yolov8")

from ultralytics import YOLO

model = YOLO('yolov8m.pt')  # or 'yolov8s.pt' for faster but slightly less accurate
model.train(data="/content/DL-YOLO-V5-6/data.yaml", epochs=100, imgsz=640, batch=16)

# ✅ Best model will be saved here:
# runs/detect/train/weights/best.pt

"""# YOLOv8m Testing"""

from google.colab import drive
drive.mount('/content/drive')

# ✅ Step 1: Install Ultralytics YOLOv8 if not already installed
!pip install -q ultralytics

# ✅ Step 2: Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# ✅ Step 3: Import required libraries
from ultralytics import YOLO
import matplotlib.pyplot as plt
import cv2
import os
from glob import glob

# ✅ Step 4: Define model path and image folder from Google Drive
model_path = '/content/best (2).pt'  # Update if needed
image_folder = '/content/drive/MyDrive/TESTING IMAGES FOLDER /Images for Testing'  # <- Your Google Drive image folder

# ✅ Step 5: Load model
model = YOLO(model_path)

# ✅ Step 6: Collect all images (jpg, png)
image_paths = glob(os.path.join(image_folder, '*.jpg')) + glob(os.path.join(image_folder, '*.png'))

# ✅ Step 7: Check image availability
print(f"Found {len(image_paths)} images.")
if not image_paths:
    raise ValueError("No images found in the specified Google Drive folder.")

# ✅ Step 8: Run inference on all images
results = model(image_paths, save=True, imgsz=640, conf=0.7)

# ✅ Step 9: Display each result one by one
for i, path in enumerate(image_paths):
    output_dir = results[i].save_dir  # YOLO stores in /runs/detect/predict, predict2, etc.
    output_img_path = os.path.join(output_dir, os.path.basename(path))

    img = cv2.imread(output_img_path)
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    plt.figure(figsize=(8, 8))
    plt.imshow(img_rgb)
    plt.axis('off')
    plt.title(f"Result {i+1}: {os.path.basename(path)}")
    plt.show()











"""#  Curent YOLOv8m Training"""



!pip install ultralytics roboflow

!pip install roboflow

from roboflow import Roboflow
rf = Roboflow(api_key="otK6vYnKBd28x5kqa8zS")
project = rf.workspace("rsfesfdse").project("dl-yolo-v5")
version = project.version(6)
dataset = version.download("yolov8")

from ultralytics import YOLO

model = YOLO('yolov8m.pt')  # or 'yolov8s.pt' for faster but slightly less accurate
model.train(data="/content/DL-YOLO-V5-6/data.yaml", epochs=100, imgsz=640, batch=16)

# ✅ Best model will be saved here:
# runs/detect/train/weights/best.pt

"""# YOLOv8m Testing"""

from google.colab import drive
drive.mount('/content/drive')

# ✅ Step 1: Install Ultralytics YOLOv8 if not already installed
!pip install -q ultralytics

# ✅ Step 2: Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# ✅ Step 3: Import required libraries
from ultralytics import YOLO
import matplotlib.pyplot as plt
import cv2
import os
from glob import glob
from PIL import Image, ExifTags

# ✅ Step 4: Define model path and image folder from Google Drive
model_path = '/content/best (2).pt'  # Update if needed
image_folder = '/content/drive/MyDrive/TEAM 36 BALAGBAG/Images for Testing'  # Make sure to include trailing slash

# ✅ Step 5: Collect all image paths
image_paths = glob(os.path.join(image_folder, '*.jpg')) + glob(os.path.join(image_folder, '*.png'))

print(f"Found {len(image_paths)} images.")
if not image_paths:
    raise ValueError("No images found in the specified Google Drive folder.")

# ✅ Step 6: Auto-rotate images using EXIF metadata
def correct_image_orientation(image_path):
    try:
        image = Image.open(image_path)
        for orientation in ExifTags.TAGS.keys():
            if ExifTags.TAGS[orientation] == 'Orientation':
                break
        exif = image._getexif()
        if exif is not None and orientation in exif:
            if exif[orientation] == 3:
                image = image.rotate(180, expand=True)
            elif exif[orientation] == 6:
                image = image.rotate(270, expand=True)
            elif exif[orientation] == 8:
                image = image.rotate(90, expand=True)
            image.save(image_path)
    except Exception as e:
        print(f"EXIF correction failed for {image_path}: {e}")

# ✅ Step 7: Apply orientation fix to all images before inference
for img_path in image_paths:
    correct_image_orientation(img_path)

# ✅ Step 8: Load YOLOv8 model
model = YOLO(model_path)

# ✅ Step 9: Run inference on all images
results = model(image_paths, save=True, imgsz=640, conf=0.7)

# ✅ Step 10: Display each result
for i, path in enumerate(image_paths):
    output_dir = results[i].save_dir
    output_img_path = os.path.join(output_dir, os.path.basename(path))

    img = cv2.imread(output_img_path)
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    plt.figure(figsize=(10, 6))  # Landscape aspect ratio
    plt.imshow(img_rgb)
    plt.axis('off')
    plt.title(f"Result {i+1}: {os.path.basename(path)}")
    plt.show()